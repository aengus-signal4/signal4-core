"""
S3 Content Checker - Shared utility for checking content file existence in S3.

This module provides a unified interface for checking what files exist for content
in S3 storage. It's used by:
- PipelineManager.evaluate_content_state()
- PipelineManager.bulk_reconcile_content_states()
- ContentAuditor
- StateAuditor

The key abstraction is ContentFileIndex which builds an index of all files for
a content item once, then provides efficient lookups.
"""

import re
import logging
from dataclasses import dataclass, field
from typing import Dict, Set, Optional, List, Any
from collections import defaultdict

from src.storage.s3_utils import S3Storage, S3StorageConfig
from src.utils.logger import setup_worker_logger

logger = setup_worker_logger('s3_content_checker')


@dataclass
class ContentFileIndex:
    """
    Index of all files for a single content item in S3.

    Built once, then queried multiple times for efficient existence checks.
    """
    content_id: str
    all_files: Set[str] = field(default_factory=set)

    # Derived/cached properties
    _prefix: str = field(init=False, default="")

    def __post_init__(self):
        self._prefix = f"content/{self.content_id}/"

    # --- Source/Audio Files ---

    @property
    def has_source_files(self) -> bool:
        """Check if any source files exist (original downloaded content)."""
        source_extensions = ['.mp4', '.mp3', '.wav', '.m4a', '.webm', '.mkv']
        for ext in source_extensions:
            if f"{self._prefix}source{ext}" in self.all_files:
                return True
            if f"{self._prefix}video{ext}" in self.all_files:
                return True
        return False

    @property
    def has_audio(self) -> bool:
        """Check if audio file exists (any format)."""
        return (
            f"{self._prefix}audio.wav" in self.all_files or
            f"{self._prefix}audio.opus" in self.all_files or
            f"{self._prefix}audio.mp3" in self.all_files
        )

    @property
    def has_storage_manifest(self) -> bool:
        """Check if storage manifest exists (indicates compressed content)."""
        return f"{self._prefix}storage_manifest.json" in self.all_files

    # --- Diarization Files ---

    @property
    def has_diarization(self) -> bool:
        """Check if diarization.json exists."""
        return (
            f"{self._prefix}diarization.json" in self.all_files or
            f"{self._prefix}diarization.json.gz" in self.all_files
        )

    @property
    def has_speaker_embeddings(self) -> bool:
        """Check if speaker_embeddings.json exists (generated by stitch)."""
        return (
            f"{self._prefix}speaker_embeddings.json" in self.all_files or
            f"{self._prefix}speaker_embeddings.json.gz" in self.all_files
        )

    @property
    def has_speaker_mapping(self) -> bool:
        """Check if speaker_mapping.json exists."""
        return (
            f"{self._prefix}speaker_mapping.json" in self.all_files or
            f"{self._prefix}speaker_mapping.json.gz" in self.all_files
        )

    # --- Stitch Output Files ---

    @property
    def has_stitched_transcript(self) -> bool:
        """Check if transcript_diarized.json exists (stitch output)."""
        return (
            f"{self._prefix}transcript_diarized.json" in self.all_files or
            f"{self._prefix}transcript_diarized.json.gz" in self.all_files
        )

    @property
    def has_semantic_segments(self) -> bool:
        """Check if semantic_segments.json exists."""
        return (
            f"{self._prefix}semantic_segments.json" in self.all_files or
            f"{self._prefix}semantic_segments.json.gz" in self.all_files
        )

    # --- Chunk Files ---

    def get_chunk_files(self) -> Dict[int, Set[str]]:
        """Get all chunk files organized by chunk index."""
        chunk_files: Dict[int, Set[str]] = defaultdict(set)
        chunk_pattern = re.compile(rf"{re.escape(self._prefix)}chunks/(\d+)/(.+)")

        for file_path in self.all_files:
            if match := chunk_pattern.match(file_path):
                chunk_index = int(match.group(1))
                filename = match.group(2)
                chunk_files[chunk_index].add(filename)

        return dict(chunk_files)

    def has_chunk_audio(self, chunk_index: int) -> bool:
        """Check if a specific chunk has audio.wav."""
        return f"{self._prefix}chunks/{chunk_index}/audio.wav" in self.all_files

    def has_chunk_transcript(self, chunk_index: int) -> bool:
        """Check if a specific chunk has transcript_words.json."""
        return (
            f"{self._prefix}chunks/{chunk_index}/transcript_words.json" in self.all_files or
            f"{self._prefix}chunks/{chunk_index}/transcript_words.json.gz" in self.all_files
        )

    def get_chunk_indices_with_audio(self) -> Set[int]:
        """Get all chunk indices that have audio.wav files."""
        chunk_pattern = re.compile(rf"{re.escape(self._prefix)}chunks/(\d+)/audio\.wav")
        indices = set()
        for file_path in self.all_files:
            if match := chunk_pattern.match(file_path):
                indices.add(int(match.group(1)))
        return indices

    def get_chunk_indices_with_transcripts(self) -> Set[int]:
        """Get all chunk indices that have transcript files."""
        chunk_pattern = re.compile(rf"{re.escape(self._prefix)}chunks/(\d+)/transcript_words\.json(\.gz)?")
        indices = set()
        for file_path in self.all_files:
            if match := chunk_pattern.match(file_path):
                indices.add(int(match.group(1)))
        return indices

    # --- Summary Methods ---

    def get_state_summary(self) -> Dict[str, Any]:
        """Get a summary of content state based on files."""
        chunk_files = self.get_chunk_files()
        chunks_with_audio = self.get_chunk_indices_with_audio()
        chunks_with_transcripts = self.get_chunk_indices_with_transcripts()

        return {
            'content_id': self.content_id,
            'total_files': len(self.all_files),
            'has_source': self.has_source_files,
            'has_audio': self.has_audio,
            'has_diarization': self.has_diarization,
            'has_stitched': self.has_stitched_transcript,
            'has_segments': self.has_semantic_segments,
            'has_manifest': self.has_storage_manifest,
            'chunk_count': len(chunk_files),
            'chunks_with_audio': len(chunks_with_audio),
            'chunks_with_transcripts': len(chunks_with_transcripts),
        }


class S3ContentChecker:
    """
    Utility class for checking content files in S3.

    Provides methods for:
    - Building file indices for single content items
    - Building bulk file indices for all content
    - Common file existence patterns
    """

    def __init__(self, s3_storage: S3Storage):
        """
        Initialize with an S3Storage instance.

        Args:
            s3_storage: Configured S3Storage instance
        """
        self.s3_storage = s3_storage

    @classmethod
    def from_config(cls, config: Dict[str, Any]) -> 'S3ContentChecker':
        """Create an S3ContentChecker from config dict."""
        s3_config = S3StorageConfig(
            endpoint_url=config['storage']['s3']['endpoint_url'],
            access_key=config['storage']['s3']['access_key'],
            secret_key=config['storage']['s3']['secret_key'],
            bucket_name=config['storage']['s3']['bucket_name'],
            use_ssl=config['storage']['s3']['use_ssl']
        )
        return cls(S3Storage(s3_config))

    def get_content_file_index(self, content_id: str) -> ContentFileIndex:
        """
        Build a file index for a single content item.

        Args:
            content_id: The content ID to index

        Returns:
            ContentFileIndex with all files for this content
        """
        prefix = f"content/{content_id}/"
        try:
            files = set(self.s3_storage.list_files(prefix))
            logger.debug(f"Found {len(files)} files for content {content_id}")
            return ContentFileIndex(content_id=content_id, all_files=files)
        except Exception as e:
            logger.error(f"Error listing files for {content_id}: {e}")
            return ContentFileIndex(content_id=content_id, all_files=set())

    def get_bulk_file_index(self, minio_client, bucket_name: str) -> Dict[str, ContentFileIndex]:
        """
        Build file indices for all content items efficiently.

        Uses MinIO client directly for better performance on large buckets.

        Args:
            minio_client: MinIO client instance
            bucket_name: S3 bucket name

        Returns:
            Dict mapping content_id to ContentFileIndex
        """
        logger.info("Building bulk file index from S3...")
        file_index: Dict[str, Set[str]] = defaultdict(set)

        try:
            # List all objects in content/ prefix
            objects = minio_client.list_objects(
                bucket_name,
                prefix='content/',
                recursive=True
            )

            # Index files by content_id
            for obj in objects:
                path_parts = obj.object_name.split('/')
                if len(path_parts) >= 2:
                    content_id = path_parts[1]
                    file_index[content_id].add(obj.object_name)

            logger.info(f"Indexed files for {len(file_index)} content items")

            # Convert to ContentFileIndex objects
            result = {}
            for content_id, files in file_index.items():
                result[content_id] = ContentFileIndex(
                    content_id=content_id,
                    all_files=files
                )

            return result

        except Exception as e:
            logger.error(f"Error building bulk file index: {e}")
            return {}

    def check_downloaded_state(self, index: ContentFileIndex) -> bool:
        """
        Check if content should be considered 'downloaded'.

        Content is downloaded if source files exist, audio exists,
        or storage manifest exists (compressed content).
        """
        return index.has_source_files or index.has_audio or index.has_storage_manifest

    def check_converted_state(self, index: ContentFileIndex, db_chunks: List[Any] = None) -> bool:
        """
        Check if content should be considered 'converted'.

        Converted means audio exists AND either:
        - Chunk audio files exist, OR
        - Transcript files exist (chunks cleaned up post-compression)

        Args:
            index: ContentFileIndex for the content
            db_chunks: Optional list of ContentChunk objects from database
        """
        if not index.has_audio:
            return False

        # Check if chunk audio exists
        chunks_with_audio = index.get_chunk_indices_with_audio()
        if chunks_with_audio:
            return True

        # Check if transcripts exist (post-cleanup case)
        chunks_with_transcripts = index.get_chunk_indices_with_transcripts()
        if chunks_with_transcripts:
            logger.debug(f"No chunk audio but {len(chunks_with_transcripts)} transcript files exist - assuming post-cleanup")
            return True

        return False

"""Add embedding column to speaker_transcriptions

Revision ID: d15077ab54ee
Revises: c04e112f84f0
Create Date: 2025-04-30 09:39:38.938061

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = 'd15077ab54ee'
down_revision: Union[str, None] = 'c04e112f84f0'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('source',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('name', sa.String(), nullable=False),
    sa.Column('type', sa.String(), nullable=False),
    sa.Column('url', sa.String(), nullable=False),
    sa.Column('projects', sa.String(), nullable=False),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('meta_data', sa.JSON(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.Column('updated_at', sa.DateTime(), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('idx_source_projects', 'source', ['projects'], unique=False)
    op.create_index('idx_source_type', 'source', ['type'], unique=False)
    op.create_table('task_queue',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('task_type', sa.String(length=50), nullable=False),
    sa.Column('content_id', sa.String(length=255), nullable=False),
    sa.Column('status', sa.String(length=20), nullable=False),
    sa.Column('worker_id', sa.String(length=100), nullable=True),
    sa.Column('input_data', sa.JSON(), nullable=False),
    sa.Column('result', sa.JSON(), nullable=True),
    sa.Column('error', sa.Text(), nullable=True),
    sa.Column('priority', sa.Integer(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('started_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('completed_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('last_heartbeat', sa.DateTime(timezone=True), nullable=True),
    sa.Column('attempts', sa.Integer(), nullable=True),
    sa.Column('max_attempts', sa.Integer(), nullable=True),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('content_id', 'task_type', name='task_queue_content_id_task_type_key'),
    schema='tasks'
    )
    op.create_index('idx_task_queue_claim', 'task_queue', ['status', 'task_type', 'priority', 'created_at'], unique=False, schema='tasks', postgresql_where=sa.text("status = 'pending'"))
    op.create_index('idx_task_queue_content_id', 'task_queue', ['content_id'], unique=False, schema='tasks')
    op.create_index('idx_task_queue_status', 'task_queue', ['status'], unique=False, schema='tasks')
    op.create_index('idx_task_queue_task_type', 'task_queue', ['task_type'], unique=False, schema='tasks')
    op.create_table('worker_config',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('hostname', sa.String(length=255), nullable=False),
    sa.Column('enabled_tasks', sa.ARRAY(sa.String()), nullable=False),
    sa.Column('max_concurrent_tasks', sa.Integer(), nullable=True),
    sa.Column('last_heartbeat', sa.DateTime(timezone=True), nullable=True),
    sa.Column('status', sa.String(length=20), nullable=True),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('hostname'),
    schema='tasks'
    )
    op.create_index('idx_worker_config_hostname', 'worker_config', ['hostname'], unique=False, schema='tasks')
    op.create_index('idx_worker_config_status', 'worker_config', ['status'], unique=False, schema='tasks')
    op.create_table('narrative_analysis',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('content_id', sa.Integer(), nullable=False),
    sa.Column('analysis_date', sa.DateTime(), nullable=True),
    sa.Column('theme_level_1', sa.String(), nullable=True),
    sa.Column('theme_level_2', sa.String(), nullable=True),
    sa.Column('theme_level_3', sa.String(), nullable=True),
    sa.Column('confidence_score', sa.Float(), nullable=True),
    sa.Column('relevant_segments', sa.JSON(), nullable=True),
    sa.Column('meta_data', sa.JSON(), nullable=True),
    sa.ForeignKeyConstraint(['content_id'], ['content.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('narrative_detections',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('segment_id', sa.String(), nullable=False),
    sa.Column('narrative_l1', sa.String(), nullable=True),
    sa.Column('narrative_l2', sa.String(), nullable=True),
    sa.Column('confidence', sa.Integer(), nullable=True),
    sa.Column('validation_status', sa.Integer(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.ForeignKeyConstraint(['segment_id'], ['entity_segment.segment_id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('idx_narrative_detections_l1', 'narrative_detections', ['narrative_l1'], unique=False)
    op.create_index('idx_narrative_detections_l2', 'narrative_detections', ['narrative_l2'], unique=False)
    op.create_index('idx_narrative_detections_segment', 'narrative_detections', ['segment_id'], unique=False)
    op.drop_index('idx_speaker_embeddings_content', table_name='speaker_embeddings')
    op.drop_table('speaker_embeddings')
    op.alter_column('content', 'publish_date',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True)
    op.alter_column('content', 'download_date',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('content', 'meta_data',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=True)
    op.alter_column('content', 'is_diarized',
               existing_type=sa.BOOLEAN(),
               nullable=True,
               existing_server_default=sa.text('false'))
    op.alter_column('content', 'chunks_status',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=True,
               existing_server_default=sa.text("'{}'::jsonb"))
    op.drop_index('idx_content_channel_url', table_name='content')
    op.drop_index('idx_content_conversion_status', table_name='content')
    op.drop_index('idx_content_download_status', table_name='content')
    op.drop_index('idx_content_processing_priority', table_name='content')
    op.drop_index('idx_content_publish_date', table_name='content')
    op.drop_index('idx_content_transcription_status', table_name='content')
    op.create_index('idx_content_blocked_download', 'content', ['blocked_download'], unique=False)
    op.create_index('idx_content_channel', 'content', ['channel_name'], unique=False)
    op.create_index('idx_content_is_converted', 'content', ['is_converted'], unique=False)
    op.create_index('idx_content_is_downloaded', 'content', ['is_downloaded'], unique=False)
    op.create_index('idx_content_is_duplicate', 'content', ['is_duplicate'], unique=False)
    op.create_index('idx_content_is_transcribed', 'content', ['is_transcribed'], unique=False)
    op.create_index(op.f('ix_content_is_embedded'), 'content', ['is_embedded'], unique=False)
    op.create_index(op.f('ix_content_is_identified'), 'content', ['is_identified'], unique=False)
    op.create_index(op.f('ix_content_is_stitched'), 'content', ['is_stitched'], unique=False)
    op.alter_column('content_chunks', 'extraction_attempts',
               existing_type=sa.INTEGER(),
               nullable=True,
               existing_server_default=sa.text('0'))
    op.drop_index('idx_chunks_chunk_index', table_name='content_chunks')
    op.drop_index('idx_chunks_content_id', table_name='content_chunks')
    op.drop_index('idx_chunks_extraction_status', table_name='content_chunks')
    op.drop_index('idx_chunks_last_updated', table_name='content_chunks')
    op.drop_index('idx_chunks_transcription_status', table_name='content_chunks')
    op.create_index('idx_content_chunks_content', 'content_chunks', ['content_id'], unique=False)
    op.create_index('idx_content_chunks_extraction_status', 'content_chunks', ['extraction_status'], unique=False)
    op.create_index('idx_content_chunks_index', 'content_chunks', ['chunk_index'], unique=False)
    op.create_index('idx_content_chunks_last_updated', 'content_chunks', ['last_updated'], unique=False)
    op.create_index('idx_content_chunks_transcription_status', 'content_chunks', ['transcription_status'], unique=False)
    op.alter_column('entity_segment', 'meta_data',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=True)
    op.alter_column('entity_segment', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('entity_segment', 'updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.drop_index('idx_entity_segment_transcription', table_name='entity_segment')
    op.alter_column('search_history', 'search_date',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.drop_index('idx_search_history_channel', table_name='search_history')
    op.drop_index('idx_search_history_dates', table_name='search_history')
    op.add_column('speaker_transcriptions', sa.Column('embedding', pgvector.sqlalchemy.vector.VECTOR(dim=1024), nullable=True))
    op.create_index('idx_speaker_transcription_time', 'speaker_transcriptions', ['content_id', 'start_time', 'end_time'], unique=False)
    op.create_index('idx_speaker_transcription_turn_index', 'speaker_transcriptions', ['content_id', 'turn_index'], unique=False)
    op.create_index(op.f('ix_speaker_transcriptions_content_id'), 'speaker_transcriptions', ['content_id'], unique=False)
    op.create_index(op.f('ix_speaker_transcriptions_speaker_id'), 'speaker_transcriptions', ['speaker_id'], unique=False)
    op.alter_column('speakers', 'embedding',
               existing_type=pgvector.sqlalchemy.vector.VECTOR(dim=256),
               nullable=False)
    op.alter_column('speakers', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True,
               existing_server_default=sa.text('now()'))
    op.alter_column('speakers', 'updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True,
               existing_server_default=sa.text('now()'))
    op.alter_column('speakers', 'total_segments',
               existing_type=sa.INTEGER(),
               nullable=True,
               existing_server_default=sa.text('0'))
    op.alter_column('speakers', 'total_duration',
               existing_type=sa.DOUBLE_PRECISION(precision=53),
               nullable=True,
               existing_server_default=sa.text("'0'::double precision"))
    op.alter_column('speakers', 'last_seen',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True)
    op.alter_column('speakers', 'appearance_count',
               existing_type=sa.INTEGER(),
               nullable=True,
               existing_server_default=sa.text('0'))
    op.alter_column('speakers', 'meta_data',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               nullable=True,
               existing_server_default=sa.text("'{}'::jsonb"))
    op.drop_index('idx_speakers_embedding', table_name='speakers', postgresql_using='ivfflat')
    op.alter_column('transcription', 'segments',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=False)
    op.alter_column('transcription', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('transcription', 'updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.drop_index('idx_transcription_content_id', table_name='transcription')
    op.create_index('idx_transcription_content', 'transcription', ['content_id'], unique=False)
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index('idx_transcription_content', table_name='transcription')
    op.create_index('idx_transcription_content_id', 'transcription', ['content_id'], unique=False)
    op.alter_column('transcription', 'updated_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('transcription', 'created_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('transcription', 'segments',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=False)
    op.create_index('idx_speakers_embedding', 'speakers', ['embedding'], unique=False, postgresql_using='ivfflat')
    op.alter_column('speakers', 'meta_data',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               nullable=False,
               existing_server_default=sa.text("'{}'::jsonb"))
    op.alter_column('speakers', 'appearance_count',
               existing_type=sa.INTEGER(),
               nullable=False,
               existing_server_default=sa.text('0'))
    op.alter_column('speakers', 'last_seen',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True)
    op.alter_column('speakers', 'total_duration',
               existing_type=sa.DOUBLE_PRECISION(precision=53),
               nullable=False,
               existing_server_default=sa.text("'0'::double precision"))
    op.alter_column('speakers', 'total_segments',
               existing_type=sa.INTEGER(),
               nullable=False,
               existing_server_default=sa.text('0'))
    op.alter_column('speakers', 'updated_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True,
               existing_server_default=sa.text('now()'))
    op.alter_column('speakers', 'created_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True,
               existing_server_default=sa.text('now()'))
    op.alter_column('speakers', 'embedding',
               existing_type=pgvector.sqlalchemy.vector.VECTOR(dim=256),
               nullable=True)
    op.drop_index(op.f('ix_speaker_transcriptions_speaker_id'), table_name='speaker_transcriptions')
    op.drop_index(op.f('ix_speaker_transcriptions_content_id'), table_name='speaker_transcriptions')
    op.drop_index('idx_speaker_transcription_turn_index', table_name='speaker_transcriptions')
    op.drop_index('idx_speaker_transcription_time', table_name='speaker_transcriptions')
    op.drop_column('speaker_transcriptions', 'embedding')
    op.create_index('idx_search_history_dates', 'search_history', ['min_date', 'max_date'], unique=False)
    op.create_index('idx_search_history_channel', 'search_history', ['channel_url'], unique=False)
    op.alter_column('search_history', 'search_date',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.create_index('idx_entity_segment_transcription', 'entity_segment', ['transcription_id'], unique=False)
    op.alter_column('entity_segment', 'updated_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('entity_segment', 'created_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('entity_segment', 'meta_data',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=True)
    op.drop_index('idx_content_chunks_transcription_status', table_name='content_chunks')
    op.drop_index('idx_content_chunks_last_updated', table_name='content_chunks')
    op.drop_index('idx_content_chunks_index', table_name='content_chunks')
    op.drop_index('idx_content_chunks_extraction_status', table_name='content_chunks')
    op.drop_index('idx_content_chunks_content', table_name='content_chunks')
    op.create_index('idx_chunks_transcription_status', 'content_chunks', ['transcription_status'], unique=False)
    op.create_index('idx_chunks_last_updated', 'content_chunks', ['last_updated'], unique=False)
    op.create_index('idx_chunks_extraction_status', 'content_chunks', ['extraction_status'], unique=False)
    op.create_index('idx_chunks_content_id', 'content_chunks', ['content_id'], unique=False)
    op.create_index('idx_chunks_chunk_index', 'content_chunks', ['chunk_index'], unique=False)
    op.alter_column('content_chunks', 'extraction_attempts',
               existing_type=sa.INTEGER(),
               nullable=False,
               existing_server_default=sa.text('0'))
    op.drop_index(op.f('ix_content_is_stitched'), table_name='content')
    op.drop_index(op.f('ix_content_is_identified'), table_name='content')
    op.drop_index(op.f('ix_content_is_embedded'), table_name='content')
    op.drop_index('idx_content_is_transcribed', table_name='content')
    op.drop_index('idx_content_is_duplicate', table_name='content')
    op.drop_index('idx_content_is_downloaded', table_name='content')
    op.drop_index('idx_content_is_converted', table_name='content')
    op.drop_index('idx_content_channel', table_name='content')
    op.drop_index('idx_content_blocked_download', table_name='content')
    op.create_index('idx_content_transcription_status', 'content', ['is_transcribed'], unique=False)
    op.create_index('idx_content_publish_date', 'content', ['publish_date'], unique=False)
    op.create_index('idx_content_processing_priority', 'content', ['processing_priority'], unique=False)
    op.create_index('idx_content_download_status', 'content', ['is_downloaded', 'blocked_download'], unique=False)
    op.create_index('idx_content_conversion_status', 'content', ['is_converted'], unique=False)
    op.create_index('idx_content_channel_url', 'content', ['channel_url'], unique=False)
    op.alter_column('content', 'chunks_status',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=True,
               existing_server_default=sa.text("'{}'::jsonb"))
    op.alter_column('content', 'is_diarized',
               existing_type=sa.BOOLEAN(),
               nullable=False,
               existing_server_default=sa.text('false'))
    op.alter_column('content', 'meta_data',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=True)
    op.alter_column('content', 'download_date',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('content', 'publish_date',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True)
    op.create_table('speaker_embeddings',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('speaker_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('content_id', sa.VARCHAR(length=255), autoincrement=False, nullable=False),
    sa.Column('embedding', postgresql.BYTEA(), autoincrement=False, nullable=False),
    sa.Column('segment_count', sa.INTEGER(), server_default=sa.text('1'), autoincrement=False, nullable=False),
    sa.Column('total_duration', sa.DOUBLE_PRECISION(precision=53), server_default=sa.text("'0'::double precision"), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['speaker_id'], ['speakers.id'], name='speaker_embeddings_speaker_id_fkey'),
    sa.PrimaryKeyConstraint('id', name='speaker_embeddings_pkey')
    )
    op.create_index('idx_speaker_embeddings_content', 'speaker_embeddings', ['content_id'], unique=False)
    op.drop_index('idx_narrative_detections_segment', table_name='narrative_detections')
    op.drop_index('idx_narrative_detections_l2', table_name='narrative_detections')
    op.drop_index('idx_narrative_detections_l1', table_name='narrative_detections')
    op.drop_table('narrative_detections')
    op.drop_table('narrative_analysis')
    op.drop_index('idx_worker_config_status', table_name='worker_config', schema='tasks')
    op.drop_index('idx_worker_config_hostname', table_name='worker_config', schema='tasks')
    op.drop_table('worker_config', schema='tasks')
    op.drop_index('idx_task_queue_task_type', table_name='task_queue', schema='tasks')
    op.drop_index('idx_task_queue_status', table_name='task_queue', schema='tasks')
    op.drop_index('idx_task_queue_content_id', table_name='task_queue', schema='tasks')
    op.drop_index('idx_task_queue_claim', table_name='task_queue', schema='tasks', postgresql_where=sa.text("status = 'pending'"))
    op.drop_table('task_queue', schema='tasks')
    op.drop_index('idx_source_type', table_name='source')
    op.drop_index('idx_source_projects', table_name='source')
    op.drop_table('source')
    # ### end Alembic commands ###
